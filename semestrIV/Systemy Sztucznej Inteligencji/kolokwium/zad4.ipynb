{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import pandas as pd \n",
    "import random \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessingData:\n",
    "    # zwracam dataframe w losowej kolejności i resetuje indeksy\n",
    "    @staticmethod\n",
    "    def shuffleDF(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        return df.iloc[random.sample(range(len(df)), len(df))].reset_index(drop=True)\n",
    "\n",
    "    # normalizuje każdą kolumnę w dataframe (według przekazanej listy) metodą min max\n",
    "    @staticmethod\n",
    "    def normalizeDF(df: pd.DataFrame, columnNames: list) -> pd.DataFrame:\n",
    "        for columnName in columnNames:\n",
    "            df[columnName] = (df[columnName]-df[columnName].min())/(df[columnName].max()-df[columnName].min())\n",
    "        return df\n",
    "\n",
    "    # zwracam wiersze gdzie index jest mniejszy od długość df*wielkość df i wiersze gdzie index jest równy lub większy od długość *wielkość df \n",
    "    @staticmethod\n",
    "    def splitDF(df: pd.DataFrame, trainSize: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        return df[df.index < int(len(df)*trainSize)], df[df.index >= int(len(df)*trainSize)]\n",
    "\n",
    "    @staticmethod\n",
    "    def processData(df: pd.DataFrame, columnNames: list, trainSize: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        df = ProcessingData.shuffleDF(df)\n",
    "        df = ProcessingData.normalizeDF(df, columnNames)\n",
    "        return ProcessingData.splitDF(df, trainSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KNN:\n",
    "    def __init__(self, k: int):\n",
    "        self.k = k\n",
    "    \n",
    "    #liczę dystatns przy użyciu metryki taksówkowej\n",
    "    @staticmethod\n",
    "    def dst(x: list, y: list) -> float:\n",
    "        return sum([(abs(xi-yi))\n",
    "                    for xi,yi in zip(x,y)])\n",
    "\n",
    "    #do obiektu wpisuje dane treningowe\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "    \n",
    "    #dla danego obiektu zwraca najczęściej pojawianego się sąsiada\n",
    "    def predict(self, point: pd.DataFrame) -> str:\n",
    "        #tworzę słownik z typami\n",
    "        types = {}\n",
    "        for v in pd.unique(self.df[\"Type\"]):\n",
    "            types[v] = 0\n",
    "        result = []\n",
    "        # liczę odległości od każdego punktu\n",
    "        for sample in self.df.values:\n",
    "            result.append([KNN.dst(sample[:-1], point), sample[-1]])\n",
    "        #sortuje odległości\n",
    "        result.sort(key=lambda x:x[0])\n",
    "        # zliczam type k najbliższych odległości\n",
    "        for i in range(self.k):\n",
    "            types[result[i][1]] += 1\n",
    "        return max(types, key=types.get)\n",
    "    \n",
    "    #liczę wynik dla zbioru testowego\n",
    "    def score(self, test_X: pd.DataFrame) -> float:\n",
    "        good = 0\n",
    "        bad = 0\n",
    "        for sample in test_X.values:\n",
    "            # sprawdzam czy predict zwrócił dobry typ\n",
    "            if (x:=self.predict(sample)) == sample[-1]:\n",
    "                good += 1\n",
    "            else:\n",
    "                bad +=1\n",
    "        return good/(bad+good)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.5\n"
     ]
    }
   ],
   "source": [
    "# znormalizowane\n",
    "seeds = pd.read_csv(\"seeds.csv\", sep=\",\")\n",
    "X_train, X_test = ProcessingData.processData(seeds, seeds.columns[:-1], 0.8)\n",
    "knn = KNN(4)\n",
    "knn.fit(X_train)\n",
    "print(knn.score(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0\n"
     ]
    }
   ],
   "source": [
    "# bez normalizacji\n",
    "seeds = pd.read_csv(\"seeds.csv\", sep=\",\")\n",
    "seeds = ProcessingData.shuffleDF(seeds)\n",
    "X_train, X_test = ProcessingData.splitDF(seeds, 0.8)\n",
    "knn = KNN(4)\n",
    "knn.fit(X_train)\n",
    "print(knn.score(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
