{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = pd.read_csv(\"seeds.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessingData:\n",
    "    # zwracam dataframe w losowej kolejności i resetuje indeksy\n",
    "    @staticmethod\n",
    "    def shuffleDF(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        return df.iloc[random.sample(range(len(df)), len(df))].reset_index(drop=True)\n",
    "\n",
    "    # normalizuje każdą kolumnę w dataframe (według przekazanej listy) metodą min max\n",
    "    @staticmethod\n",
    "    def normalizeDF(df: pd.DataFrame, columnNames: list) -> pd.DataFrame:\n",
    "        for columnName in columnNames:\n",
    "            df[columnName] = (df[columnName]-df[columnName].min())/(df[columnName].max()-df[columnName].min())\n",
    "        return df\n",
    "\n",
    "    # zwracam wiersze gdzie index jest mniejszy od długość df*wielkość df i wiersze gdzie index jest równy lub większy od długość *wielkość df \n",
    "    @staticmethod\n",
    "    def splitDF(df: pd.DataFrame, trainSize: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        return df[df.index < int(len(df)*trainSize)], df[df.index >= int(len(df)*trainSize)]\n",
    "\n",
    "    @staticmethod\n",
    "    def processData(df: pd.DataFrame, columnNames: list, trainSize: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        df = ProcessingData.shuffleDF(df)\n",
    "        df = ProcessingData.normalizeDF(df, columnNames)\n",
    "        return ProcessingData.splitDF(df, trainSize)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    # przygotowuje dane potrzebne do obliczeń takie jak prawdopodobieństwo średnia i odchylenie standardowe dla wszystkich typów\n",
    "    def __init__(self, df: pd.DataFrame) -> None:\n",
    "        self.dataTypes = df.iloc[:, -1].unique()\n",
    "        self.dataSplitted = {k : df[df[\"Type\"] == k].iloc[:, :-1] for k in self.dataTypes}\n",
    "        self.columnNames = df.columns[:-1]\n",
    "        self.probDict = {k : len(self.dataSplitted[k])/len(df) for k in self.dataTypes}\n",
    "        self.meanDict = {k : self.dataSplitted[k].mean() for k in self.dataTypes}\n",
    "        self.stdDict = {k : self.dataSplitted[k].std() for k in self.dataTypes}\n",
    "    \n",
    "    # obliczam według wzoru podanego w zadaniu    \n",
    "    @staticmethod\n",
    "    def gauss(x, classMean, classStd) -> float:\n",
    "        if x < classMean - classStd*6**(1/2):\n",
    "            return 0\n",
    "        elif x <= classMean:\n",
    "            return (x-classMean)/(6*(classStd**2)) + 1/((6**(1/2)) * classStd)\n",
    "        elif x <= classMean + classStd**(1/2):\n",
    "            return -(x-classMean)/(6*(classStd**2)) + 1/((6**(1/2)) * classStd)\n",
    "        else: \n",
    "            return 0\n",
    "\n",
    "    # liczę prawdopodbieństwo każej klasy dla przekazanej próbki \n",
    "    def predict(self, sample: pd.core.series):\n",
    "        result = {}\n",
    "        for d in self.dataTypes:\n",
    "            prob = self.probDict[d]\n",
    "            for column in range(len(self.columnNames)):\n",
    "                prob *= self.gauss(sample[column], self.meanDict[d][column], self.stdDict[d][column])\n",
    "            result[d] = prob\n",
    "        return max(result, key=result.get)\n",
    "    \n",
    "    #obliczam wynik    \n",
    "    def score(self, X_test: pd.DataFrame):\n",
    "        good, bad = 0, 0\n",
    "        for sample in X_test.values:\n",
    "            #porównuje wynik z oczekiwanym\n",
    "            if (x:=self.predict(sample)) == sample[-1]:\n",
    "                good += 1\n",
    "            else:\n",
    "                bad +=1\n",
    "        return good/(bad+good)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0\n"
     ]
    }
   ],
   "source": [
    "# z normalizacja\n",
    "train_X, test_X = ProcessingData.processData(seeds, seeds.columns[:-1], 0.8)\n",
    "bayes = NaiveBayes(train_X)\n",
    "print(bayes.score(test_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.0\n"
     ]
    }
   ],
   "source": [
    "# bez normalizacji\n",
    "seeds = pd.read_csv(\"seeds.csv\", sep=\",\")\n",
    "seeds = ProcessingData.shuffleDF(seeds)\n",
    "train_X, test_X = ProcessingData.splitDF(seeds, 0.8)\n",
    "bayes = NaiveBayes(train_X)\n",
    "print(bayes.score(test_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
